<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>VAE | XR_Wang</title><meta name="keywords" content="生成模型_学习"><meta name="author" content="XR_Wang"><meta name="copyright" content="XR_Wang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Unsupervised Learning - Deep Generative Model参考链接： https://www.bilibili.com/video/BV1Wv411h7kN?p=65&amp;vd_source=909d7728ce838d2b9656fb13a31483ca https://www.bilibili.com/video/BV1Wv411h7kN?p=66&amp;">
<meta property="og:type" content="article">
<meta property="og:title" content="VAE">
<meta property="og:url" content="http://example.com/2022/10/15/VAE/index.html">
<meta property="og:site_name" content="XR_Wang">
<meta property="og:description" content="Unsupervised Learning - Deep Generative Model参考链接： https://www.bilibili.com/video/BV1Wv411h7kN?p=65&amp;vd_source=909d7728ce838d2b9656fb13a31483ca https://www.bilibili.com/video/BV1Wv411h7kN?p=66&amp;">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://w.wallhaven.cc/full/7p/wallhaven-7pgd5y.png">
<meta property="article:published_time" content="2022-10-15T07:51:02.000Z">
<meta property="article:modified_time" content="2022-11-04T12:40:51.506Z">
<meta property="article:author" content="XR_Wang">
<meta property="article:tag" content="生成模型_学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://w.wallhaven.cc/full/7p/wallhaven-7pgd5y.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2022/10/15/VAE/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'VAE',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-11-04 20:40:51'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/modify.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://w.wallhaven.cc/full/eo/wallhaven-eolx9o.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://w.wallhaven.cc/full/7p/wallhaven-7pgd5y.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">XR_Wang</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">VAE</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-10-15T07:51:02.000Z" title="发表于 2022-10-15 15:51:02">2022-10-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-04T12:40:51.506Z" title="更新于 2022-11-04 20:40:51">2022-11-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F/">研究生</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>10分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="VAE"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url('https://w.wallhaven.cc/full/7p/wallhaven-7pgd5y.png');"></div><article class="post-content" id="article-container"><h1 id="Unsupervised-Learning-Deep-Generative-Model"><a href="#Unsupervised-Learning-Deep-Generative-Model" class="headerlink" title="Unsupervised Learning - Deep Generative Model"></a>Unsupervised Learning - Deep Generative Model</h1><p>参考链接：</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Wv411h7kN?p=65&amp;vd_source=909d7728ce838d2b9656fb13a31483ca">https://www.bilibili.com/video/BV1Wv411h7kN?p=65&amp;vd_source=909d7728ce838d2b9656fb13a31483ca</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Wv411h7kN?p=66&amp;spm_id_from=pageDriver&amp;vd_source=909d7728ce838d2b9656fb13a31483ca">https://www.bilibili.com/video/BV1Wv411h7kN?p=66&amp;spm_id_from=pageDriver&amp;vd_source=909d7728ce838d2b9656fb13a31483ca</a></p>
<h2 id="Theory-behind-VAE"><a href="#Theory-behind-VAE" class="headerlink" title="Theory behind VAE"></a>Theory behind VAE</h2><p><img src="/imgs/VAE1.png" alt=""></p>
<p>提出VAE的直觉：</p>
<p><img src="/imgs/VAE2.png" alt=""></p>
<p><img src="/imgs/why VAE.png" alt=""></p>
<p><img src="/imgs/VAe3.png" alt=""></p>
<p>若使$\sum_{i=1}^3{\left( e^{\sigma _i}-\left( 1+\sigma _i \right) +\left( m_i \right) ^2 \right)}$最小化，则$\sigma _i$应该趋近于0，则方差$e^{\sigma _i}$趋近于1。$m_i$为均值，$m_i$趋近于0，故<em>q(z|x)</em>趋近于均值为0，方差为1的分布。由于对于任一个X，所有的 <em>p</em>(<em>Z</em>|<em>X</em>) 都很接近标准正态分布 <em>N</em>(0,<em>I</em>)。也就是下面这个推导：</p>
<p><img src="/imgs/VAE14.webp" alt=""></p>
<p>这样我们就能达到我们的先验假设：<em>p</em>(<em>Z</em>) 是标准正态分布。然后我们就可以放心地从 <em>N</em>(0,<em>I</em>) 中采样来生成图像了。</p>
<p>上面这个式子在博客下半部分也提到了。这里再放一篇博客，有利于理解VAE：<a target="_blank" rel="noopener" href="https://blog.csdn.net/a312863063/article/details/87953517">https://blog.csdn.net/a312863063/article/details/87953517</a></p>
<p><img src="/imgs/VAE4.png" alt=""></p>
<p><img src="/imgs/VAE5.png" alt=""></p>
<p><img src="/imgs/VAE6.png" alt=""></p>
<p><img src="/imgs/VAE7.png" alt=""></p>
<p><img src="/imgs/VAE8.png" alt=""></p>
<p><img src="/imgs/VAE9.png" alt=""></p>
<p><img src="/imgs/VAE10.png" alt=""></p>
<p><img src="/imgs/VAE11.png" alt=""></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>However, we’re trying to build a generative model here, not just a fuzzy data structure that can “memorize” images. We can’t generate anything yet, since we don’t know how to create latent vectors other than encoding them from images.</p>
<p>There’s a simple solution here. We add a constraint on the encoding network, that forces it to generate latent vectors that roughly follow a unit gaussian distribution. It is this constraint that separates a variational autoencoder from a standard one.</p>
<p>Generating new images is now easy: all we need to do is sample a latent vector from the unit gaussian and pass it into the decoder.</p>
<p>We let the network decide this itself. For our loss term, we sum up two separate losses: the generative loss, which is a mean squared error that measures how accurately the network reconstructed the images, and a latent loss, which is the KL divergence that measures how closely the latent variables match a unit gaussian.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">generation_loss = mean(square(generated_image - real_image))</span><br><span class="line">latent_loss = KL-Divergence(latent_variable, unit_gaussian)</span><br><span class="line">loss = generation_loss + latent_loss</span><br></pre></td></tr></tbody></table></figure>
<p>In order to optimize the KL divergence, we need to apply a simple reparameterization trick: instead of the encoder generating a vector of real values, it will generate a vector of means and a vector of standard deviations.</p>
<p>A downside to the VAE is that it uses direct mean squared error instead of an adversarial network, so the network tends to produce more blurry images.</p>
<p>There’s been some work looking into combining the VAE and the GAN: Using the same encoder-decoder setup, but using an adversarial network as a metric for training the decoder.</p>
<h2 id="Problems-of-VAE"><a href="#Problems-of-VAE" class="headerlink" title="Problems of VAE"></a>Problems of VAE</h2><p><img src="/imgs/VAE12.png" alt=""></p>
<h1 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h1><p><a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2018-08-12-vae/">https://lilianweng.github.io/posts/2018-08-12-vae/</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34998569">https://zhuanlan.zhihu.com/p/34998569</a></p>
<p><a target="_blank" rel="noopener" href="https://kvfrans.com/variational-autoencoders-explained/">https://kvfrans.com/variational-autoencoders-explained/</a></p>
<p><a target="_blank" rel="noopener" href="https://spaces.ac.cn/archives/5343">https://spaces.ac.cn/archives/5343</a></p>
<p><a target="_blank" rel="noopener" href="https://spaces.ac.cn/archives/7725">https://spaces.ac.cn/archives/7725</a></p>
<p><strong>那我怎么找出专属于</strong> <strong>$X_k$</strong> <strong>的正态分布</strong> <strong>p(Z|$X_k$) 的均值和方差呢？</strong>好像并没有什么直接的思路。</p>
<p>那好吧，<strong>我就用神经网络来拟合出来</strong>。这就是神经网络时代的哲学：难算的我们都用神经网络来拟合，在 WGAN 那里我们已经体验过一次了，现在再次体验到了。</p>
<p>于是我们构建两个神经网络 <em>$μ_k$</em>=<em>f</em>1(<em>$X_k$</em>)，log<em>$σ^2$</em>=<em>f</em>2(<em>$X_k$</em>) 来算它们了。我们选择拟合 log<em>$σ^2$</em> 而不是直接拟合 <em>$σ^2$</em>，是因为 <em>$σ^2$</em> 总是非负的，需要加激活函数处理，而拟合 log<em>$σ^2$</em> 不需要加激活函数，因为它可正可负。</p>
<p>到这里，我能知道专属于 <em>$X_k$</em> 的均值和方差了，也就知道它的正态分布长什么样了，然后从这个专属分布中采样一个 <em>$Z_k$</em> 出来，然后经过一个生成器得到 <em>$\hat{X}_k$</em>=<em>g</em>(<em>$Z_k$</em>)。</p>
<p>现在我们可以放心地最小化 <em>$D(\hat{X}_k,X_k)^2$</em>，因为 <em>$Z_k$</em> 是从专属 <em>$X_k$</em> 的分布中采样出来的，这个生成器应该要把开始的 <em>$X_k$</em> 还原回来。</p>
<p><img src="/imgs/VAE13.webp" alt=""></p>
<p>VAE 是为每个样本构造专属的正态分布，然后采样来重构。</p>
<p><strong>其实 VAE 还让所有的</strong> <strong>p(Z|X) 都向标准正态分布看齐</strong>，这样就防止了噪声为零，同时保证了模型具有生成能力。</p>
<p><img src="/imgs/VAE14.webp" alt=""></p>
<p>这样我们就能达到我们的先验假设：<em>p</em>(<em>Z</em>) 是标准正态分布。然后我们就可以放心地从 <em>N</em>(0,<em>I</em>) 中采样来生成图像了。</p>
<p><img src="/imgs/VAE15.webp" alt=""></p>
<p>怎么让所有的 <em>p</em>(<em>Z</em>|<em>X</em>) 都向 <em>N</em>(0,<em>I</em>) 看齐呢？</p>
<p>原论文直接算了一般（各分量独立的）正态分布与标准正态分布的 KL 散度<em>KL</em>(<em>N</em>(<em>μ</em>,<em>$σ^2$</em>)‖<em>N</em>(0,<em>I</em>))作为这个额外的 loss，计算结果为：</p>
<p><img src="/imgs/VAE16.webp" alt=""></p>
<p><strong>重参数技巧</strong></p>
<p>最后是实现模型的一个技巧，英文名是 Reparameterization Trick，我这里叫它做重参数吧。</p>
<p><img src="/imgs/VAE17.jfif" alt=""></p>
<p>就是我们要从 <em>p</em>(<em>Z</em>|<em>$X_k$</em>) 中采样一个 <em>$Z_k$</em> 出来，尽管我们知道了 <em>p</em>(<em>Z</em>|<em>$X_k$</em>) 是正态分布，但是均值方差都是靠模型算出来的，我们要靠这个过程反过来优化均值方差的模型，但是“采样”这个操作是不可导的，而采样的结果是可导的，于是我们利用了一个事实：</p>
<p><img src="/imgs/VAE18.jfif" alt=""></p>
<p>所以，我们将从 <em>N</em>(<em>μ</em>,<em>$σ^2$</em>) 采样变成了从 <em>N</em>(<em>0</em>,<em>$1$</em>) 中采样，然后通过参数变换得到从<em>N</em>(<em>μ</em>,<em>$σ^2$</em>) 中采样的结果。这样一来，“采样”这个操作就不用参与梯度下降了，改为采样的结果参与，使得整个模型可训练了。</p>
<hr>
<p>中间插入一部分，这段为个人理解：</p>
<p>如何进行采样操作？如下图。输入任意一个样本$X_k$，这个$X_k$对应的分布<em>p(z|$X_k$)</em>的均值为$\mu _k$，方差为$e^{\sigma _k}$。从分布均值为$\mu _k$，方差为$e^{\sigma _k}$的分布中进行采样这个操作，通过换一种方式进行，即先从<em>N(0,I)</em>中采样个$\varepsilon$，然后<em>$z\,\,=\,\,\mu _k\,\,+\,\,\varepsilon \times e^{\sigma _k}$</em> ，也就实现了采样这个操作，后来随着训练进行，均值为$\mu _k$，方差$e^{\sigma _k}$都趋近于0。<em>p(z|$X_k$)</em>在最大化<em>$-KL(q(z|x)||P(z))$</em>的操作下与$P(z)$接近，且$q(z|x)$的均值趋近于0，方差趋近于1，因此$P(z)$的均值趋近于0，方差趋近于1，也符合一开始<strong>“假设服从标准的正态分布，那么我就可以从中采样得到若干个 Z1,Z2,…,Zn，然后对它做变换得到 X̂1=g(Z1),X̂2=g(Z2),…,X̂n=g(Zn)”</strong>这个假设。</p>
<p><img src="/imgs/VAE20.png" alt=""></p>
<p>而<em>p(z|$X_k$)</em>的引入，是为了辅助求解<em>P(x|z)</em>，而<em>P(z)</em>是标准正态分布，故进而可以最大化$P\left( x \right) \,\,=\,\,\int\limits_z{P\left( z \right) P\left( x|z \right) dz}$。<em>P(x|z)</em>这一部分是decoder，不断调整<em>P(x|z)</em>使<em>P(x)</em>最大，其中蕴含了<strong>高斯混合模型</strong>的思想。如下图：</p>
<p><img src="/imgs/VAE21.png" alt=""></p>
<p><img src="/imgs/VAE22.png" alt=""></p>
<hr>
<p>事实上，我觉得 <strong>VAE 从让普通人望而生畏的变分和贝叶斯理论出发，最后落地到一个具体的模型中</strong>，虽然走了比较长的一段路，但最终的模型其实是很接地气的。</p>
<p><strong>它本质上就是在我们常规的自编码器的基础上，对 encoder 的结果（在VAE中对应着计算均值的网络）加上了“高斯噪声”，使得结果 decoder 能够对噪声有鲁棒性；而那个额外的 KL loss（目的是让均值为 0，方差为 1），事实上就是相当于对 encoder 的一个正则项，希望 encoder 出来的东西均有零均值。</strong></p>
<p>那另外一个 encoder（对应着计算方差的网络）的作用呢？它是用来<strong>动态调节噪声的强度</strong>的。</p>
<p>直觉上来想，<strong>当 decoder 还没有训练好时（重构误差远大于 KL loss），就会适当降低噪声（KL loss 增加），使得拟合起来容易一些（重构误差开始下降）</strong>。</p>
<p>反之，<strong>如果 decoder 训练得还不错时（重构误差小于 KL loss），这时候噪声就会增加（KL loss 减少），使得拟合更加困难了（重构误差又开始增加），这时候 decoder 就要想办法提高它的生成能力了</strong>。</p>
<p><img src="/imgs/VAE19.jfif" alt=""></p>
<h1 id="pytorch代码"><a href="#pytorch代码" class="headerlink" title="pytorch代码"></a>pytorch代码</h1><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> distributions</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, D_in, H, latent_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, H)</span><br><span class="line">        self.enc_mu = torch.nn.Linear(H, latent_size)</span><br><span class="line">        self.enc_log_sigma = torch.nn.Linear(H, latent_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.linear1(x))</span><br><span class="line">        x = F.relu(self.linear2(x))</span><br><span class="line">        mu = self.enc_mu(x)</span><br><span class="line">        log_sigma = self.enc_log_sigma(x)</span><br><span class="line">        sigma = torch.exp(log_sigma)</span><br><span class="line">        <span class="keyword">return</span> torch.distributions.Normal(loc=mu, scale=sigma)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, D_in, H, D_out</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, D_out)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.linear1(x))</span><br><span class="line">        mu = torch.tanh(self.linear2(x))</span><br><span class="line">        <span class="keyword">return</span> torch.distributions.Normal(mu, torch.ones_like(mu))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VAE</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, encoder, decoder</span>):</span><br><span class="line">        <span class="built_in">super</span>(VAE, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, state</span>):</span><br><span class="line">        q_z = self.encoder(state)</span><br><span class="line">        z = q_z.rsample()      <span class="comment">#rsample()不是在定义的正太分布上采样，而是先对标准正太分布N(0,1)进行采样，然后输出:mean+std×采样值</span></span><br><span class="line">        <span class="keyword">return</span> self.decoder(z), q_z</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     <span class="comment"># Normalize the images to be -0.5, 0.5</span></span><br><span class="line">     transforms.Normalize(<span class="number">0.5</span>, <span class="number">1</span>)]</span><br><span class="line">    )</span><br><span class="line">mnist = torchvision.datasets.MNIST(<span class="string">'./'</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">input_dim = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">hidden_size = <span class="number">512</span></span><br><span class="line">latent_size = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">'cuda'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    device = torch.device(<span class="string">'cpu'</span>)</span><br><span class="line"></span><br><span class="line">dataloader = torch.utils.data.DataLoader(</span><br><span class="line">    mnist, batch_size=batch_size,</span><br><span class="line">    shuffle=<span class="literal">True</span>, </span><br><span class="line">    pin_memory=torch.cuda.is_available())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Number of samples: '</span>, <span class="built_in">len</span>(mnist))</span><br><span class="line"></span><br><span class="line">encoder = Encoder(input_dim, hidden_size, latent_size)</span><br><span class="line">decoder = Decoder(latent_size, hidden_size, input_dim)</span><br><span class="line"></span><br><span class="line">vae = VAE(encoder, decoder).to(device)</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(vae.parameters(), lr=learning_rate)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">        inputs, _ = data</span><br><span class="line">        inputs = inputs.view(-<span class="number">1</span>, input_dim).to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        p_x, q_z = vae(inputs)</span><br><span class="line">        log_likelihood = p_x.log_prob(inputs).<span class="built_in">sum</span>(-<span class="number">1</span>).mean()    <span class="comment">#logprob = dist.log_prob(sample) means to get the logarithmic probability (logprob) of one experiment sample (sample) under a specific distribution (dist).</span></span><br><span class="line">        kl = torch.distributions.kl_divergence(                 <span class="comment">#Log probability: https://en.wikipedia.org/wiki/Log_probability</span></span><br><span class="line">            q_z, </span><br><span class="line">            torch.distributions.Normal(<span class="number">0</span>, <span class="number">1.</span>)</span><br><span class="line">        ).<span class="built_in">sum</span>(-<span class="number">1</span>).mean()</span><br><span class="line">        loss = -(log_likelihood - kl)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        l = loss.item()</span><br><span class="line">    <span class="built_in">print</span>(epoch, l, log_likelihood.item(), kl.item())</span><br></pre></td></tr></tbody></table></figure>
<p>A tensor has multiple dimensions, ordered as in the following figure. There is a forward and backward indexing. Forward indexing uses positive integers, backward indexing uses negative integers.</p>
<p>Example:</p>
<p>-1 will be the last one, in our case it will be dim=2</p>
<p>-2 will be dim=1</p>
<p>-3 will be dim=0</p>
<p><img src="/imgs/VAE23.png" alt=""></p>
<h1 id="CVAE"><a href="#CVAE" class="headerlink" title="CVAE"></a>CVAE</h1><p><a target="_blank" rel="noopener" href="https://agustinus.kristia.de/techblog/2016/12/17/conditional-vae/">https://agustinus.kristia.de/techblog/2016/12/17/conditional-vae/</a></p>
<h1 id="VAE-GAN"><a href="#VAE-GAN" class="headerlink" title="VAE-GAN"></a>VAE-GAN</h1><p><a target="_blank" rel="noopener" href="http://www.twistedwg.com/2018/01/31/VAE+GAN.html">http://www.twistedwg.com/2018/01/31/VAE+GAN.html</a></p>
<p><img src="/imgs/vae-gan.png" alt=""></p>
<p><img src="/imgs/vae-gan2.png" alt=""></p>
<h1 id="VQ-VAE"><a href="#VQ-VAE" class="headerlink" title="VQ-VAE"></a>VQ-VAE</h1><p><a target="_blank" rel="noopener" href="https://spaces.ac.cn/archives/6760">https://spaces.ac.cn/archives/6760</a></p>
<h1 id="为什么-p-z-得是标准正态分布呢？"><a href="#为什么-p-z-得是标准正态分布呢？" class="headerlink" title="为什么$p(z)$得是标准正态分布呢？"></a>为什么$p(z)$得是标准正态分布呢？</h1><p>其实不一定，因为这个是先验分布，人为定义的。</p>
<p><a target="_blank" rel="noopener" href="https://aitechtogether.com/article/8412.html">https://aitechtogether.com/article/8412.html</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">XR_Wang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/10/15/VAE/">http://example.com/2022/10/15/VAE/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">XR_Wang</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B-%E5%AD%A6%E4%B9%A0/">生成模型_学习</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/7p/wallhaven-7pgd5y.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/10/18/Flow-models/"><img class="prev-cover" src="https://w.wallhaven.cc/full/yx/wallhaven-yx7rld.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Flow_models</div></div></a></div><div class="next-post pull-right"><a href="/2022/10/14/zotero/"><img class="next-cover" src="https://w.wallhaven.cc/full/md/wallhaven-mdo2p1.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">zotero</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/10/18/Flow-models/" title="Flow_models"><img class="cover" src="https://w.wallhaven.cc/full/yx/wallhaven-yx7rld.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-18</div><div class="title">Flow_models</div></div></a></div><div><a href="/2022/10/25/GAN-PPT/" title="GAN_PPT"><img class="cover" src="https://w.wallhaven.cc/full/o5/wallhaven-o5921p.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-25</div><div class="title">GAN_PPT</div></div></a></div><div><a href="/2022/10/31/VAE-PPT/" title="VAE-PPT"><img class="cover" src="https://w.wallhaven.cc/full/4g/wallhaven-4g68d7.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-31</div><div class="title">VAE-PPT</div></div></a></div><div><a href="/2022/11/13/diffusion-PPT/" title="diffusion_PPT"><img class="cover" src="https://w.wallhaven.cc/full/l8/wallhaven-l8qy8l.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-13</div><div class="title">diffusion_PPT</div></div></a></div><div><a href="/2022/11/07/diffusion/" title="diffusion"><img class="cover" src="https://w.wallhaven.cc/full/nr/wallhaven-nr85j4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">diffusion</div></div></a></div><div><a href="/2022/11/07/flow-based-PPT/" title="flow_based_PPT"><img class="cover" src="https://w.wallhaven.cc/full/4d/wallhaven-4d3reo.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">flow_based_PPT</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://w.wallhaven.cc/full/eo/wallhaven-eolx9o.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">XR_Wang</div><div class="author-info__description">也无风雨也无晴</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/wxrui182"><i class="fab fa-github"></i><span>GitHub</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><p align="center"><b><font color="#e66b6d">自</font> <font color="#e66d98">强</font> <font color="#e66cc6">不</font> <font color="#cc6de6">息</font></b></p> <p align="center"><img src="https://up.54fcnr.com/pic_source/e0/79/b2/e079b26ce42cf3019b17ac29f337f15a.gif" width="50" alt="mao"></p> <p align="center">QQ邮箱：2233134941@qq.com</p></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Unsupervised-Learning-Deep-Generative-Model"><span class="toc-number">1.</span> <span class="toc-text">Unsupervised Learning - Deep Generative Model</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Theory-behind-VAE"><span class="toc-number">1.1.</span> <span class="toc-text">Theory behind VAE</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.1.1.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Problems-of-VAE"><span class="toc-number">1.2.</span> <span class="toc-text">Problems of VAE</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%9A%E5%AE%A2"><span class="toc-number">2.</span> <span class="toc-text">博客</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch%E4%BB%A3%E7%A0%81"><span class="toc-number">3.</span> <span class="toc-text">pytorch代码</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CVAE"><span class="toc-number">4.</span> <span class="toc-text">CVAE</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#VAE-GAN"><span class="toc-number">5.</span> <span class="toc-text">VAE-GAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#VQ-VAE"><span class="toc-number">6.</span> <span class="toc-text">VQ-VAE</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88-p-z-%E5%BE%97%E6%98%AF%E6%A0%87%E5%87%86%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E5%91%A2%EF%BC%9F"><span class="toc-number">7.</span> <span class="toc-text">为什么$p(z)$得是标准正态分布呢？</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/12/12/%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" title="各式各样的自注意力机制"><img src="https://static.runoob.com/images/demo/demo2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="各式各样的自注意力机制"></a><div class="content"><a class="title" href="/2022/12/12/%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" title="各式各样的自注意力机制">各式各样的自注意力机制</a><time datetime="2022-12-12T07:33:42.000Z" title="发表于 2022-12-12 15:33:42">2022-12-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/03/%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E8%B0%83%E7%A0%94%E7%AC%AC%E4%B8%80%E5%BC%B9/" title="视频生成调研第一弹"><img src="https://w.wallhaven.cc/full/5d/wallhaven-5dq2z9.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="视频生成调研第一弹"></a><div class="content"><a class="title" href="/2022/12/03/%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E8%B0%83%E7%A0%94%E7%AC%AC%E4%B8%80%E5%BC%B9/" title="视频生成调研第一弹">视频生成调研第一弹</a><time datetime="2022-12-03T07:42:23.000Z" title="发表于 2022-12-03 15:42:23">2022-12-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/13/diffusion-PPT/" title="diffusion_PPT"><img src="https://w.wallhaven.cc/full/l8/wallhaven-l8qy8l.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="diffusion_PPT"></a><div class="content"><a class="title" href="/2022/11/13/diffusion-PPT/" title="diffusion_PPT">diffusion_PPT</a><time datetime="2022-11-13T14:39:05.000Z" title="发表于 2022-11-13 22:39:05">2022-11-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/07/diffusion/" title="diffusion"><img src="https://w.wallhaven.cc/full/nr/wallhaven-nr85j4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="diffusion"></a><div class="content"><a class="title" href="/2022/11/07/diffusion/" title="diffusion">diffusion</a><time datetime="2022-11-07T06:40:30.000Z" title="发表于 2022-11-07 14:40:30">2022-11-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/07/flow-based-PPT/" title="flow_based_PPT"><img src="https://w.wallhaven.cc/full/4d/wallhaven-4d3reo.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="flow_based_PPT"></a><div class="content"><a class="title" href="/2022/11/07/flow-based-PPT/" title="flow_based_PPT">flow_based_PPT</a><time datetime="2022-11-07T03:05:30.000Z" title="发表于 2022-11-07 11:05:30">2022-11-07</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">©2020 - 2022 By XR_Wang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax="">
  function butterfly_clock_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_injector_config();
  }
  </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax="" src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.js"></script><!-- hexo injector body_end end --></body></html>