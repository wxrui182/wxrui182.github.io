<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>GAN | XR_Wang</title><meta name="keywords" content="生成模型_学习"><meta name="author" content="XR_Wang"><meta name="copyright" content="XR_Wang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="GAN博客内容One neural network tries to generate realistic data (note that GANs can be used to model any data distribution, but are mainly used for images these days), and the other network tries to discri">
<meta property="og:type" content="article">
<meta property="og:title" content="GAN">
<meta property="og:url" content="http://example.com/2022/10/09/GAN/index.html">
<meta property="og:site_name" content="XR_Wang">
<meta property="og:description" content="GAN博客内容One neural network tries to generate realistic data (note that GANs can be used to model any data distribution, but are mainly used for images these days), and the other network tries to discri">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://w.wallhaven.cc/full/gp/wallhaven-gpzymd.png">
<meta property="article:published_time" content="2022-10-09T08:25:57.000Z">
<meta property="article:modified_time" content="2022-10-21T14:54:05.818Z">
<meta property="article:author" content="XR_Wang">
<meta property="article:tag" content="生成模型_学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://w.wallhaven.cc/full/gp/wallhaven-gpzymd.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2022/10/09/GAN/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'GAN',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-10-21 22:54:05'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/modify.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://w.wallhaven.cc/full/eo/wallhaven-eolx9o.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://w.wallhaven.cc/full/gp/wallhaven-gpzymd.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">XR_Wang</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">GAN</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-10-09T08:25:57.000Z" title="发表于 2022-10-09 16:25:57">2022-10-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-10-21T14:54:05.818Z" title="更新于 2022-10-21 22:54:05">2022-10-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F/">研究生</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="GAN"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url('https://w.wallhaven.cc/full/gp/wallhaven-gpzymd.png');"></div><article class="post-content" id="article-container"><h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><h2 id="博客内容"><a href="#博客内容" class="headerlink" title="博客内容"></a>博客内容</h2><p>One neural network tries to <strong>generate</strong> realistic data (note that GANs can be used to model any data distribution, but are mainly used for images these days), and the other network tries to <strong>discriminate</strong> between real data and data generated by the generator network.</p>
<p>The generator network uses the discriminator as a loss function and updates its parameters to generate data that starts to look more realistic.</p>
<p>The discriminator network, on the other hand, updates its parameters to make itself better at picking out fake data from real data. So it too gets better at its job.</p>
<p>The game of cat and mouse continues, until the system reaches a so-called “equilibrium,” where the generator creates data that looks real enough that the best the discriminator can do is guess randomly.</p>
<p>一个神经网络尝试生成真实数据（请注意，GANs 可用于对任何数据分布进行建模，但目前主要用于图像），另一个网络尝试区分真实数据和生成器网络生成的数据。</p>
<p>生成器网络使用鉴别器作为损失函数并更新其参数以生成开始看起来更真实的数据。</p>
<p>另一方面，鉴别器网络会更新其参数，以使自己更好地从真实数据中挑选出虚假数据。因此，它的工作也变得更好。</p>
<p>猫捉老鼠的游戏继续进行，直到系统达到所谓的“平衡”，在这种平衡中，生成器创建的数据看起来足够真实，鉴别器所能做的最好的事情就是随机猜测。</p>
<h2 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h2><p>标准的GAN训练循环有三个步骤：</p>
<ol>
<li>用真实的训练数据集训练鉴别器。</li>
<li>用生成的数据训练鉴别器。</li>
<li>训练生成器生成数据，并使鉴别器以为它是真实数据。</li>
</ol>
<p><img src="/imgs/gan14.png" alt=""></p>
<p>provide higher gradient in the early stage of training:</p>
<p><img src="/imgs/gan15.png" alt=""></p>
<h2 id="视频参考"><a href="#视频参考" class="headerlink" title="视频参考"></a>视频参考</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Wv411h7kN?p=62&amp;vd_source=909d7728ce838d2b9656fb13a31483ca">https://www.bilibili.com/video/BV1Wv411h7kN?p=62&amp;vd_source=909d7728ce838d2b9656fb13a31483ca</a></p>
<h3 id="Theory-behind-GAN"><a href="#Theory-behind-GAN" class="headerlink" title="Theory behind GAN"></a>Theory behind GAN</h3><p>应使$P_G$和$P_{data}$这两个分布尽可能靠近(下图公式中<em>Div</em>是divergence)：</p>
<p><img src="/imgs/gan1.png" alt=""></p>
<p>$P_G$和$P_{data}$这两个分布，我们并不知道它俩长什么样子，但是可以从这两个分布中采样：</p>
<p><img src="/imgs/gan2.png" alt=""></p>
<p>目标函数如下：</p>
<p><img src="/imgs/gan3.png" alt=""></p>
<p>Optimizing G is equal to minimizing the JS distance:</p>
<ul>
<li><img src="/imgs/gan4.png" alt=""></li>
<li><img src="/imgs/gan5.png" alt=""></li>
<li><img src="/imgs/gan6.png" alt=""></li>
<li><img src="/imgs/gan7.png" alt=""></li>
</ul>
<p>所以$Div(P_G,P_{data})$可以被替换了：</p>
<p><img src="/imgs/gan8.png" alt=""></p>
<p>也就是：</p>
<p><img src="/imgs/gan9.png" alt=""></p>
<p>求解步骤如下：</p>
<p><img src="/imgs/gan10.png" alt=""></p>
<ol>
<li><img src="/imgs/gan11.png" alt=""></li>
<li><img src="/imgs/gan12.png" alt=""></li>
</ol>
<p>Maximize $\tilde{V}$ = Minimize Cross-entropy</p>
<p><img src="/imgs/gan13.png" alt=""></p>
<h3 id="直觉"><a href="#直觉" class="headerlink" title="直觉"></a>直觉</h3><p>蓝色分布和绿色分布不断靠近</p>
<p><img src="/imgs/gan16.png" alt=""></p>
<h2 id="pytorch代码"><a href="#pytorch代码" class="headerlink" title="pytorch代码"></a>pytorch代码</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">os.makedirs(<span class="string">"images"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"--n_epochs"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">200</span>, <span class="built_in">help</span>=<span class="string">"number of epochs of training"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--batch_size"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">64</span>, <span class="built_in">help</span>=<span class="string">"size of the batches"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--lr"</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0002</span>, <span class="built_in">help</span>=<span class="string">"adam: learning rate"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--b1"</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.5</span>, <span class="built_in">help</span>=<span class="string">"adam: decay of first order momentum of gradient"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--b2"</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.999</span>, <span class="built_in">help</span>=<span class="string">"adam: decay of first order momentum of gradient"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--n_cpu"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8</span>, <span class="built_in">help</span>=<span class="string">"number of cpu threads to use during batch generation"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--latent_dim"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>, <span class="built_in">help</span>=<span class="string">"dimensionality of the latent space"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--img_size"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">28</span>, <span class="built_in">help</span>=<span class="string">"size of each image dimension"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--channels"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>, <span class="built_in">help</span>=<span class="string">"number of image channels"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--sample_interval"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">400</span>, <span class="built_in">help</span>=<span class="string">"interval betwen image samples"</span>)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line"><span class="built_in">print</span>(opt)</span><br><span class="line"></span><br><span class="line">img_shape = (opt.channels, opt.img_size, opt.img_size)</span><br><span class="line"></span><br><span class="line">cuda = <span class="literal">True</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">block</span>(<span class="params">in_feat, out_feat, normalize=<span class="literal">True</span></span>):</span><br><span class="line">            layers = [nn.Linear(in_feat, out_feat)]</span><br><span class="line">            <span class="keyword">if</span> normalize:</span><br><span class="line">                layers.append(nn.BatchNorm1d(out_feat, <span class="number">0.8</span>))</span><br><span class="line">            layers.append(nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>))</span><br><span class="line">            <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            *block(opt.latent_dim, <span class="number">128</span>, normalize=<span class="literal">False</span>),   <span class="comment">#block返回的是一个元组，所以前面加上*就相当于给nn.Sequential传入了nn.Linear()、nn.LeakyReLU()等</span></span><br><span class="line">            *block(<span class="number">128</span>, <span class="number">256</span>),</span><br><span class="line">            *block(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            *block(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="built_in">int</span>(np.prod(img_shape))),   <span class="comment">#np.prod()返回给定轴上的数组元素的乘积</span></span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z</span>):</span><br><span class="line">        img = self.model(z)</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), *img_shape)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="built_in">int</span>(np.prod(img_shape)), <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img</span>):</span><br><span class="line">        img_flat = img.view(img.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        validity = self.model(img_flat)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> validity</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss function</span></span><br><span class="line">adversarial_loss = torch.nn.BCELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize generator and discriminator</span></span><br><span class="line">generator = Generator()</span><br><span class="line">discriminator = Discriminator()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> cuda:</span><br><span class="line">    generator.cuda()</span><br><span class="line">    discriminator.cuda()</span><br><span class="line">    adversarial_loss.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure data loader</span></span><br><span class="line">os.makedirs(<span class="string">"../../data/mnist"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">dataloader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(</span><br><span class="line">        <span class="string">"../../data/mnist"</span>,</span><br><span class="line">        train=<span class="literal">True</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transforms.Compose(</span><br><span class="line">            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>])]</span><br><span class="line">        ),</span><br><span class="line">    ),</span><br><span class="line">    batch_size=opt.batch_size,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizers</span></span><br><span class="line">optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))</span><br><span class="line">optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))</span><br><span class="line"></span><br><span class="line">Tensor = torch.cuda.FloatTensor <span class="keyword">if</span> cuda <span class="keyword">else</span> torch.FloatTensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------</span></span><br><span class="line"><span class="comment">#  Training</span></span><br><span class="line"><span class="comment"># ----------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(opt.n_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (imgs, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Adversarial ground truths</span></span><br><span class="line">        valid = Variable(Tensor(imgs.size(<span class="number">0</span>), <span class="number">1</span>).fill_(<span class="number">1.0</span>), requires_grad=<span class="literal">False</span>)   <span class="comment">#真为1</span></span><br><span class="line">        fake = Variable(Tensor(imgs.size(<span class="number">0</span>), <span class="number">1</span>).fill_(<span class="number">0.0</span>), requires_grad=<span class="literal">False</span>)    <span class="comment">#假为0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Configure input</span></span><br><span class="line">        real_imgs = Variable(imgs.<span class="built_in">type</span>(Tensor))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># -----------------</span></span><br><span class="line">        <span class="comment">#  Train Generator</span></span><br><span class="line">        <span class="comment"># -----------------</span></span><br><span class="line"></span><br><span class="line">        optimizer_G.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Sample noise as generator input</span></span><br><span class="line">        z = Variable(Tensor(np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (imgs.shape[<span class="number">0</span>], opt.latent_dim))))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Generate a batch of images</span></span><br><span class="line">        gen_imgs = generator(z)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loss measures generator's ability to fool the discriminator</span></span><br><span class="line">        g_loss = adversarial_loss(discriminator(gen_imgs), valid)</span><br><span class="line"></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        optimizer_G.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment">#  Train Discriminator</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line"></span><br><span class="line">        optimizer_D.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Measure discriminator's ability to classify real from generated samples</span></span><br><span class="line">        real_loss = adversarial_loss(discriminator(real_imgs), valid)</span><br><span class="line">        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)    <span class="comment">#detach()作用：不需要计算生成器的梯度。</span></span><br><span class="line">        d_loss = (real_loss + fake_loss) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        optimizer_D.step()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"</span></span><br><span class="line">            % (epoch, opt.n_epochs, i, <span class="built_in">len</span>(dataloader), d_loss.item(), g_loss.item())</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        batches_done = epoch * <span class="built_in">len</span>(dataloader) + i</span><br><span class="line">        <span class="keyword">if</span> batches_done % opt.sample_interval == <span class="number">0</span>:</span><br><span class="line">            save_image(gen_imgs.data[:<span class="number">25</span>], <span class="string">"images/%d.png"</span> % batches_done, nrow=<span class="number">5</span>, normalize=<span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>代码运行之后的结果展示：</p>
<p><img src="/imgs/99200.png" alt=""></p>
<h2 id="有关train-GAN的一些tips"><a href="#有关train-GAN的一些tips" class="headerlink" title="有关train GAN的一些tips"></a>有关train GAN的一些tips</h2><p><img src="/imgs/train_gan.png" alt=""></p>
<hr>
<h1 id="DCGAN-Deep-Convolutional-Generative-Adversarial-Network"><a href="#DCGAN-Deep-Convolutional-Generative-Adversarial-Network" class="headerlink" title="DCGAN: Deep Convolutional Generative Adversarial Network"></a>DCGAN: Deep Convolutional Generative Adversarial Network</h1><h2 id="博客内容-1"><a href="#博客内容-1" class="headerlink" title="博客内容"></a>博客内容</h2><p><strong>Convolutions+GANs=Good for generating images</strong></p>
<p>DCGAN changed that by using something called a transposed convolution operation or, <em>its “unfortunate” name,</em> <em>Deconvolution layer,</em>.</p>
<p>转置卷积不是卷积的逆运算，起上采样作用。</p>
<p><img src="/imgs/DCGAN.gif" alt=""></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/LoseInVain/article/details/81098502">https://blog.csdn.net/LoseInVain/article/details/81098502</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1mh411J7U4">https://www.bilibili.com/video/BV1mh411J7U4</a></p>
<p><img src="/imgs/转置卷积.png" alt=""></p>
<p><img src="/imgs/转置卷积2.png" alt=""></p>
<p><img src="/imgs/转置卷积3.png" alt=""></p>
<h2 id="要点-1"><a href="#要点-1" class="headerlink" title="要点"></a>要点</h2><ol>
<li>卷积模块缩减数据，同样配置的转置卷积模块可以抵消这种缩减。因此，转置卷积是生成网络的理想选择。</li>
<li>转置卷积卷积核在中间网格上以步长1移动，这个步长是固定的。不同于一般的卷积，这里的步长选项不用来决定卷积核的移动方式，而只用于设置原始方格在中间网格中的距离。</li>
<li>转置卷积中加入补全，与普通的卷积不同，之前补全的作用是扩展图像。在这里，补全的作用是缩小图像。</li>
</ol>
<hr>
<h1 id="CGAN-Conditional-Generative-Adversarial-Network"><a href="#CGAN-Conditional-Generative-Adversarial-Network" class="headerlink" title="CGAN: Conditional Generative Adversarial Network"></a>CGAN: Conditional Generative Adversarial Network</h1><h2 id="要点-2"><a href="#要点-2" class="headerlink" title="要点"></a>要点</h2><ol>
<li>不同于GAN，条件式GAN可以直接生成特定类型的输出。</li>
<li>训练条件式GAN，需要将类别标签分别与图像和种子一起输入鉴别器和生成器。</li>
</ol>
<p><img src="/imgs/CGAN.png" alt=""></p>
<h2 id="pytorch代码-1"><a href="#pytorch代码-1" class="headerlink" title="pytorch代码"></a>pytorch代码</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">os.makedirs(<span class="string">"images"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"--n_epochs"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">200</span>, <span class="built_in">help</span>=<span class="string">"number of epochs of training"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--batch_size"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">64</span>, <span class="built_in">help</span>=<span class="string">"size of the batches"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--lr"</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0002</span>, <span class="built_in">help</span>=<span class="string">"adam: learning rate"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--b1"</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.5</span>, <span class="built_in">help</span>=<span class="string">"adam: decay of first order momentum of gradient"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--b2"</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.999</span>, <span class="built_in">help</span>=<span class="string">"adam: decay of first order momentum of gradient"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--n_cpu"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8</span>, <span class="built_in">help</span>=<span class="string">"number of cpu threads to use during batch generation"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--latent_dim"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>, <span class="built_in">help</span>=<span class="string">"dimensionality of the latent space"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--n_classes"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>, <span class="built_in">help</span>=<span class="string">"number of classes for dataset"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--img_size"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">32</span>, <span class="built_in">help</span>=<span class="string">"size of each image dimension"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--channels"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>, <span class="built_in">help</span>=<span class="string">"number of image channels"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--sample_interval"</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">400</span>, <span class="built_in">help</span>=<span class="string">"interval between image sampling"</span>)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line"><span class="built_in">print</span>(opt)</span><br><span class="line"></span><br><span class="line">img_shape = (opt.channels, opt.img_size, opt.img_size)</span><br><span class="line"></span><br><span class="line">cuda = <span class="literal">True</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)     <span class="comment">#nn.Embedding(num_embeddings, embedding_dim)。num_embeddings (python:int) – 词典的大小尺寸，比如总共出现5000个词，那就输入5000。此时index为（0-4999） embedding_dim (python:int) – 嵌入向量的维度，即用多少维来表示一个符号。</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">block</span>(<span class="params">in_feat, out_feat, normalize=<span class="literal">True</span></span>):</span><br><span class="line">            layers = [nn.Linear(in_feat, out_feat)]</span><br><span class="line">            <span class="keyword">if</span> normalize:</span><br><span class="line">                layers.append(nn.BatchNorm1d(out_feat, <span class="number">0.8</span>))</span><br><span class="line">            layers.append(nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>))</span><br><span class="line">            <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            *block(opt.latent_dim + opt.n_classes, <span class="number">128</span>, normalize=<span class="literal">False</span>),</span><br><span class="line">            *block(<span class="number">128</span>, <span class="number">256</span>),</span><br><span class="line">            *block(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            *block(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="built_in">int</span>(np.prod(img_shape))),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, noise, labels</span>):</span><br><span class="line">        <span class="comment"># Concatenate label embedding and image to produce input</span></span><br><span class="line">        gen_input = torch.cat((self.label_emb(labels), noise), -<span class="number">1</span>)  <span class="comment">#将label embedding和noise相连接</span></span><br><span class="line">        img = self.model(gen_input)</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), *img_shape)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.label_embedding = nn.Embedding(opt.n_classes, opt.n_classes)</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(opt.n_classes + <span class="built_in">int</span>(np.prod(img_shape)), <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img, labels</span>):</span><br><span class="line">        <span class="comment"># Concatenate label embedding and image to produce input</span></span><br><span class="line">        d_in = torch.cat((img.view(img.size(<span class="number">0</span>), -<span class="number">1</span>), self.label_embedding(labels)), -<span class="number">1</span>)     <span class="comment">#将label embedding和img相连接</span></span><br><span class="line">        validity = self.model(d_in)</span><br><span class="line">        <span class="keyword">return</span> validity</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss functions</span></span><br><span class="line">adversarial_loss = torch.nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize generator and discriminator</span></span><br><span class="line">generator = Generator()</span><br><span class="line">discriminator = Discriminator()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> cuda:</span><br><span class="line">    generator.cuda()</span><br><span class="line">    discriminator.cuda()</span><br><span class="line">    adversarial_loss.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure data loader</span></span><br><span class="line">os.makedirs(<span class="string">"../../data/mnist"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">dataloader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(</span><br><span class="line">        <span class="string">"../../data/mnist"</span>,</span><br><span class="line">        train=<span class="literal">True</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transforms.Compose(</span><br><span class="line">            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>])]</span><br><span class="line">        ),</span><br><span class="line">    ),</span><br><span class="line">    batch_size=opt.batch_size,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizers</span></span><br><span class="line">optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))</span><br><span class="line">optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))</span><br><span class="line"></span><br><span class="line">FloatTensor = torch.cuda.FloatTensor <span class="keyword">if</span> cuda <span class="keyword">else</span> torch.FloatTensor</span><br><span class="line">LongTensor = torch.cuda.LongTensor <span class="keyword">if</span> cuda <span class="keyword">else</span> torch.LongTensor    <span class="comment">#64-bit integer</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_image</span>(<span class="params">n_row, batches_done</span>):</span><br><span class="line">    <span class="string">"""Saves a grid of generated digits ranging from 0 to n_classes"""</span></span><br><span class="line">    <span class="comment"># Sample noise</span></span><br><span class="line">    z = Variable(FloatTensor(np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (n_row ** <span class="number">2</span>, opt.latent_dim))))</span><br><span class="line">    <span class="comment"># Get labels ranging from 0 to n_classes for n rows</span></span><br><span class="line">    labels = np.array([num <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_row) <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(n_row)])  <span class="comment">#两个for循环，最后生成[0,1,2,...,9,0,1,2...,9,0,...]</span></span><br><span class="line">    labels = Variable(LongTensor(labels))</span><br><span class="line">    gen_imgs = generator(z, labels)</span><br><span class="line">    save_image(gen_imgs.data, <span class="string">"images/%d.png"</span> % batches_done, nrow=n_row, normalize=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------</span></span><br><span class="line"><span class="comment">#  Training</span></span><br><span class="line"><span class="comment"># ----------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(opt.n_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (imgs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">        batch_size = imgs.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Adversarial ground truths</span></span><br><span class="line">        valid = Variable(FloatTensor(batch_size, <span class="number">1</span>).fill_(<span class="number">1.0</span>), requires_grad=<span class="literal">False</span>)</span><br><span class="line">        fake = Variable(FloatTensor(batch_size, <span class="number">1</span>).fill_(<span class="number">0.0</span>), requires_grad=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Configure input</span></span><br><span class="line">        real_imgs = Variable(imgs.<span class="built_in">type</span>(FloatTensor))</span><br><span class="line">        labels = Variable(labels.<span class="built_in">type</span>(LongTensor))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># -----------------</span></span><br><span class="line">        <span class="comment">#  Train Generator</span></span><br><span class="line">        <span class="comment"># -----------------</span></span><br><span class="line"></span><br><span class="line">        optimizer_G.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Sample noise and labels as generator input</span></span><br><span class="line">        z = Variable(FloatTensor(np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, opt.latent_dim))))</span><br><span class="line">        gen_labels = Variable(LongTensor(np.random.randint(<span class="number">0</span>, opt.n_classes, batch_size)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Generate a batch of images</span></span><br><span class="line">        gen_imgs = generator(z, gen_labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loss measures generator's ability to fool the discriminator</span></span><br><span class="line">        validity = discriminator(gen_imgs, gen_labels)</span><br><span class="line">        g_loss = adversarial_loss(validity, valid)</span><br><span class="line"></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        optimizer_G.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment">#  Train Discriminator</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line"></span><br><span class="line">        optimizer_D.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loss for real images</span></span><br><span class="line">        validity_real = discriminator(real_imgs, labels)</span><br><span class="line">        d_real_loss = adversarial_loss(validity_real, valid)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loss for fake images</span></span><br><span class="line">        validity_fake = discriminator(gen_imgs.detach(), gen_labels)</span><br><span class="line">        d_fake_loss = adversarial_loss(validity_fake, fake)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Total discriminator loss</span></span><br><span class="line">        d_loss = (d_real_loss + d_fake_loss) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        optimizer_D.step()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"</span></span><br><span class="line">            % (epoch, opt.n_epochs, i, <span class="built_in">len</span>(dataloader), d_loss.item(), g_loss.item())</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        batches_done = epoch * <span class="built_in">len</span>(dataloader) + i</span><br><span class="line">        <span class="keyword">if</span> batches_done % opt.sample_interval == <span class="number">0</span>:</span><br><span class="line">            sample_image(n_row=<span class="number">10</span>, batches_done=batches_done)</span><br></pre></td></tr></tbody></table></figure>
<p>运行代码的结果如下：</p>
<p><img src="/imgs/63600.png" alt=""></p>
<hr>
<h1 id="CycleGAN"><a href="#CycleGAN" class="headerlink" title="CycleGAN"></a>CycleGAN</h1><h2 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h2><p><img src="/imgs/cyclegan.png" alt=""></p>
<p>G takes in an image from X and tries to map it to some image in Y. The discriminator $D_Y$ predicts whether an image was generated by G or was actually in Y.</p>
<p>Similarly, F takes in an image from Y and tries to map it to some image in X, And the discriminator $D_X$ predicts whether an image was generated by F or was actually in X.</p>
<p>To further improve performance, CycleGAN uses another metric, cycle consistency loss.</p>
<script type="math/tex; mode=display">
F(G(x)) \approx x, x \in X</script><script type="math/tex; mode=display">
G(F(y)) \approx y, y \in Y</script><h2 id="视频参考-1"><a href="#视频参考-1" class="headerlink" title="视频参考"></a>视频参考</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Wv411h7kN?p=61&amp;vd_source=909d7728ce838d2b9656fb13a31483ca">https://www.bilibili.com/video/BV1Wv411h7kN?p=61&amp;vd_source=909d7728ce838d2b9656fb13a31483ca</a></p>
<p>仍然使用原来的GAN可能会无视generator的输入，如下图：</p>
<p><img src="/imgs/cyclegan2.png" alt=""></p>
<p>所以就提出了Cycle GAN，结构如下：</p>
<p><img src="/imgs/cyclegan3.png" alt=""></p>
<p>为了让第二个generator能够成功还原原来的图片，第一个generator产生的图片就不能跟输入差太多。</p>
<p>下图为完整的Cycle GAN：</p>
<p><img src="/imgs/cyclegan4.png" alt=""></p>
<h1 id="CoGAN"><a href="#CoGAN" class="headerlink" title="CoGAN"></a>CoGAN</h1><hr>
<h1 id="ProGAN-Progressive-growing-of-Generative-Adversarial-Networks"><a href="#ProGAN-Progressive-growing-of-Generative-Adversarial-Networks" class="headerlink" title="ProGAN: Progressive growing of Generative Adversarial Networks"></a>ProGAN: Progressive growing of Generative Adversarial Networks</h1><h2 id="博客-1"><a href="#博客-1" class="headerlink" title="博客"></a>博客</h2><p>The intuition here is that it’s easier to generate a 4x4 image than it is to generate a 1024x1024 image. Also, it’s easier to map a 16x16 image to a 32x32 image than it is to map a 2x2 image to a 32x32 image.</p>
<p><img src="/imgs/ProGAN.gif" alt=""></p>
<hr>
<h1 id="WGAN-Wasserstein-Generative-Adversarial-Networks"><a href="#WGAN-Wasserstein-Generative-Adversarial-Networks" class="headerlink" title="WGAN: Wasserstein Generative Adversarial Networks"></a>WGAN: Wasserstein Generative Adversarial Networks</h1><h2 id="博客-2"><a href="#博客-2" class="headerlink" title="博客"></a>博客</h2><p>The Jensen-Shannon divergence is a way of measuring how different two probability distributions are.The larger the JSD, the more “different” the two distributions are, and vice versa.</p>
<script type="math/tex; mode=display">
\text{JSD}(P||Q) = \text{KL}(P || \frac{P+Q}{2}) +  \text{KL}(Q || \frac{P+Q}{2})</script><script type="math/tex; mode=display">
KL(A||B) = \int_{-\infty}^{\infty}a(x)\log{\frac{a(x)}{b(x)}} dx</script><p>The alternate distance metric proposed by the WGAN authors is the 1-Wasserstein distance, sometimes called the earth mover distance.</p>
<p><img src="/imgs/WGAN.png" alt=""></p>
<script type="math/tex; mode=display">
\mathrm{EMD}(P_r, P_\theta) = \sup_{\lVert f \lVert_{L \leq 1}} \ \mathbb{E}{x \sim P_r} f(x) - \mathbb{E}{x \sim P_\theta} f(x)</script><h2 id="理解JS散度-Jensen–Shannon-divergence"><a href="#理解JS散度-Jensen–Shannon-divergence" class="headerlink" title="理解JS散度(Jensen–Shannon divergence)"></a>理解JS散度(Jensen–Shannon divergence)</h2><h3 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h3><p><img src="/imgs/KL.png" alt=""></p>
<p>KL散度具有非负性和不对称<em>$KL(P||Q)\ne KL\left( Q||P \right) $</em>。</p>
<h3 id="JS散度"><a href="#JS散度" class="headerlink" title="JS散度"></a>JS散度</h3><p><strong>一般地</strong>，JS散度是对称的，其取值是 0 到 1 之间。如果两个分布 P,Q 离得很远，完全没有重叠的时候，那么KL散度值是没有意义的，而JS散度值是一个常数。这在学习算法中是比较致命的，这就意味这这一点的梯度为 0。<strong>梯度消失了。</strong></p>
<p><img src="/imgs/JS1.png" alt=""></p>
<p><img src="/imgs/JS2.png" alt=""></p>
<p><img src="/imgs/JS3.png" alt=""></p>
<h3 id="为什么会出现两个分布没有重叠的现象"><a href="#为什么会出现两个分布没有重叠的现象" class="headerlink" title="为什么会出现两个分布没有重叠的现象"></a>为什么会出现两个分布没有重叠的现象</h3><p><img src="/imgs/JS4.png" alt=""></p>
<h2 id="令人拍案叫绝的Wasserstein-GAN"><a href="#令人拍案叫绝的Wasserstein-GAN" class="headerlink" title="令人拍案叫绝的Wasserstein GAN"></a>令人拍案叫绝的Wasserstein GAN</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/25071913">https://zhuanlan.zhihu.com/p/25071913</a></p>
<p>上面这个博客讲得非常清楚:在第一篇《Towards Principled Methods for Training Generative Adversarial Networks》里面推了一堆公式定理，从理论上分析了原始GAN的问题所在，从而针对性地给出了改进要点；在这第二篇《Wasserstein GAN》里面，又再从这个改进点出发推了一堆公式定理，最终给出了改进的算法实现流程，<strong>而改进后相比原始GAN的算法实现流程却只改了四点</strong>：</p>
<ul>
<li>判别器最后一层去掉sigmoid</li>
<li>生成器和判别器的loss不取log</li>
<li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li>
<li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li>
</ul>
<h2 id="视频参考-2"><a href="#视频参考-2" class="headerlink" title="视频参考"></a>视频参考</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Wv411h7kN?p=64&amp;vd_source=909d7728ce838d2b9656fb13a31483ca">https://www.bilibili.com/video/BV1Wv411h7kN?p=64&amp;vd_source=909d7728ce838d2b9656fb13a31483ca</a></p>
<p>JS divergence存在着如下的问题：</p>
<p><img src="/imgs/WGAN2.png" alt=""></p>
<p>earth mover distance的定义如下：</p>
<p><img src="/imgs/WGAN3.png" alt=""></p>
<p><img src="/imgs/gan17.png" alt=""></p>
<p>中间推导过程省略，直接给出$P_{data}$和$P_G$之间的Wasserstein distance如何计算</p>
<p><img src="/imgs/WGAN4.png" alt=""></p>
<p>Lipschitz Function的直观理解：input有变化时，output的变化不会太大。</p>
<p><img src="/imgs/WGAN5.png" alt=""></p>
<p>How to fulfill this constraint?→Weight Clipping</p>
<p><img src="/imgs/WGAN6.png" alt=""></p>
<p>WGAN的训练步骤：</p>
<p><img src="/imgs/WGAN7.png" alt=""></p>
<hr>
<h1 id="SAGAN-Self-Attention-Generative-Adversarial-Networks"><a href="#SAGAN-Self-Attention-Generative-Adversarial-Networks" class="headerlink" title="SAGAN: Self-Attention Generative Adversarial Networks"></a>SAGAN: Self-Attention Generative Adversarial Networks</h1><h2 id="博客-3"><a href="#博客-3" class="headerlink" title="博客"></a>博客</h2><p>Since GANs use transposed convolutions to “scan” feature maps, they only have access to nearby information.</p>
<p>Self-attention allows the generator to take a step back and look at the “big picture.”</p>
<hr>
<h1 id="BigGAN"><a href="#BigGAN" class="headerlink" title="BigGAN"></a>BigGAN</h1><h2 id="博客-4"><a href="#博客-4" class="headerlink" title="博客"></a>博客</h2><p>The authors also train BigGAN on a new dataset called JFT-300, which is an ImageNet-like dataset which has, you guessed it, 300 million images. They showed that BigGAN perform better on this dataset, suggesting that more massive datasets might be the way to go for GANs</p>
<hr>
<h1 id="StyleGAN-Style-based-Generative-Adversarial-Networks"><a href="#StyleGAN-Style-based-Generative-Adversarial-Networks" class="headerlink" title="StyleGAN: Style-based Generative Adversarial Networks"></a>StyleGAN: Style-based Generative Adversarial Networks</h1><h2 id="博客-5"><a href="#博客-5" class="headerlink" title="博客"></a>博客</h2><p>StyleGAN is like a photoshop plugin, while most GAN developments are a new version of photoshop.</p>
<h1 id="有关GAN的参考书籍"><a href="#有关GAN的参考书籍" class="headerlink" title="有关GAN的参考书籍"></a>有关GAN的参考书籍</h1><p><img src="/imgs/pytorch_gan.png" alt=""></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">XR_Wang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/10/09/GAN/">http://example.com/2022/10/09/GAN/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">XR_Wang</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B-%E5%AD%A6%E4%B9%A0/">生成模型_学习</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/gp/wallhaven-gpzymd.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/10/14/zotero/"><img class="prev-cover" src="https://w.wallhaven.cc/full/md/wallhaven-mdo2p1.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">zotero</div></div></a></div><div class="next-post pull-right"><a href="/2022/10/06/%E5%81%87%E5%A6%82%E7%94%9F%E6%B4%BB%E6%AC%BA%E9%AA%97%E4%BA%86%E4%BD%A0/"><img class="next-cover" src="https://w.wallhaven.cc/full/l3/wallhaven-l3edjp.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">假如生活欺骗了你</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/10/18/Flow-models/" title="Flow_models"><img class="cover" src="https://w.wallhaven.cc/full/yx/wallhaven-yx7rld.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-18</div><div class="title">Flow_models</div></div></a></div><div><a href="/2022/10/15/VAE/" title="VAE"><img class="cover" src="https://w.wallhaven.cc/full/7p/wallhaven-7pgd5y.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-15</div><div class="title">VAE</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://w.wallhaven.cc/full/eo/wallhaven-eolx9o.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">XR_Wang</div><div class="author-info__description">也无风雨也无晴</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/wxrui182"><i class="fab fa-github"></i><span>GitHub</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><p align="center"><b><font color="#e66b6d">自</font> <font color="#e66d98">强</font> <font color="#e66cc6">不</font> <font color="#cc6de6">息</font></b></p> <p align="center"><img src="https://up.54fcnr.com/pic_source/e0/79/b2/e079b26ce42cf3019b17ac29f337f15a.gif" width="50" alt="mao"></p> <p align="center">QQ邮箱：2233134941@qq.com</p></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#GAN"><span class="toc-number">1.</span> <span class="toc-text">GAN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9"><span class="toc-number">1.1.</span> <span class="toc-text">博客内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A6%81%E7%82%B9"><span class="toc-number">1.2.</span> <span class="toc-text">要点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%86%E9%A2%91%E5%8F%82%E8%80%83"><span class="toc-number">1.3.</span> <span class="toc-text">视频参考</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Theory-behind-GAN"><span class="toc-number">1.3.1.</span> <span class="toc-text">Theory behind GAN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B4%E8%A7%89"><span class="toc-number">1.3.2.</span> <span class="toc-text">直觉</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pytorch%E4%BB%A3%E7%A0%81"><span class="toc-number">1.4.</span> <span class="toc-text">pytorch代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%89%E5%85%B3train-GAN%E7%9A%84%E4%B8%80%E4%BA%9Btips"><span class="toc-number">1.5.</span> <span class="toc-text">有关train GAN的一些tips</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#DCGAN-Deep-Convolutional-Generative-Adversarial-Network"><span class="toc-number">2.</span> <span class="toc-text">DCGAN: Deep Convolutional Generative Adversarial Network</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9-1"><span class="toc-number">2.1.</span> <span class="toc-text">博客内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A6%81%E7%82%B9-1"><span class="toc-number">2.2.</span> <span class="toc-text">要点</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CGAN-Conditional-Generative-Adversarial-Network"><span class="toc-number">3.</span> <span class="toc-text">CGAN: Conditional Generative Adversarial Network</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A6%81%E7%82%B9-2"><span class="toc-number">3.1.</span> <span class="toc-text">要点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pytorch%E4%BB%A3%E7%A0%81-1"><span class="toc-number">3.2.</span> <span class="toc-text">pytorch代码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CycleGAN"><span class="toc-number">4.</span> <span class="toc-text">CycleGAN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%9A%E5%AE%A2"><span class="toc-number">4.1.</span> <span class="toc-text">博客</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%86%E9%A2%91%E5%8F%82%E8%80%83-1"><span class="toc-number">4.2.</span> <span class="toc-text">视频参考</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CoGAN"><span class="toc-number">5.</span> <span class="toc-text">CoGAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ProGAN-Progressive-growing-of-Generative-Adversarial-Networks"><span class="toc-number">6.</span> <span class="toc-text">ProGAN: Progressive growing of Generative Adversarial Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%9A%E5%AE%A2-1"><span class="toc-number">6.1.</span> <span class="toc-text">博客</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#WGAN-Wasserstein-Generative-Adversarial-Networks"><span class="toc-number">7.</span> <span class="toc-text">WGAN: Wasserstein Generative Adversarial Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%9A%E5%AE%A2-2"><span class="toc-number">7.1.</span> <span class="toc-text">博客</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%90%86%E8%A7%A3JS%E6%95%A3%E5%BA%A6-Jensen%E2%80%93Shannon-divergence"><span class="toc-number">7.2.</span> <span class="toc-text">理解JS散度(Jensen–Shannon divergence)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#KL%E6%95%A3%E5%BA%A6"><span class="toc-number">7.2.1.</span> <span class="toc-text">KL散度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#JS%E6%95%A3%E5%BA%A6"><span class="toc-number">7.2.2.</span> <span class="toc-text">JS散度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E5%87%BA%E7%8E%B0%E4%B8%A4%E4%B8%AA%E5%88%86%E5%B8%83%E6%B2%A1%E6%9C%89%E9%87%8D%E5%8F%A0%E7%9A%84%E7%8E%B0%E8%B1%A1"><span class="toc-number">7.2.3.</span> <span class="toc-text">为什么会出现两个分布没有重叠的现象</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A4%E4%BA%BA%E6%8B%8D%E6%A1%88%E5%8F%AB%E7%BB%9D%E7%9A%84Wasserstein-GAN"><span class="toc-number">7.3.</span> <span class="toc-text">令人拍案叫绝的Wasserstein GAN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%86%E9%A2%91%E5%8F%82%E8%80%83-2"><span class="toc-number">7.4.</span> <span class="toc-text">视频参考</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SAGAN-Self-Attention-Generative-Adversarial-Networks"><span class="toc-number">8.</span> <span class="toc-text">SAGAN: Self-Attention Generative Adversarial Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%9A%E5%AE%A2-3"><span class="toc-number">8.1.</span> <span class="toc-text">博客</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#BigGAN"><span class="toc-number">9.</span> <span class="toc-text">BigGAN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%9A%E5%AE%A2-4"><span class="toc-number">9.1.</span> <span class="toc-text">博客</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#StyleGAN-Style-based-Generative-Adversarial-Networks"><span class="toc-number">10.</span> <span class="toc-text">StyleGAN: Style-based Generative Adversarial Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%9A%E5%AE%A2-5"><span class="toc-number">10.1.</span> <span class="toc-text">博客</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%89%E5%85%B3GAN%E7%9A%84%E5%8F%82%E8%80%83%E4%B9%A6%E7%B1%8D"><span class="toc-number">11.</span> <span class="toc-text">有关GAN的参考书籍</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/10/18/Flow-models/" title="Flow_models"><img src="https://w.wallhaven.cc/full/yx/wallhaven-yx7rld.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flow_models"></a><div class="content"><a class="title" href="/2022/10/18/Flow-models/" title="Flow_models">Flow_models</a><time datetime="2022-10-18T07:15:51.000Z" title="发表于 2022-10-18 15:15:51">2022-10-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/15/VAE/" title="VAE"><img src="https://w.wallhaven.cc/full/7p/wallhaven-7pgd5y.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VAE"></a><div class="content"><a class="title" href="/2022/10/15/VAE/" title="VAE">VAE</a><time datetime="2022-10-15T07:51:02.000Z" title="发表于 2022-10-15 15:51:02">2022-10-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/14/zotero/" title="zotero"><img src="https://w.wallhaven.cc/full/md/wallhaven-mdo2p1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="zotero"></a><div class="content"><a class="title" href="/2022/10/14/zotero/" title="zotero">zotero</a><time datetime="2022-10-14T12:09:22.000Z" title="发表于 2022-10-14 20:09:22">2022-10-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/09/GAN/" title="GAN"><img src="https://w.wallhaven.cc/full/gp/wallhaven-gpzymd.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GAN"></a><div class="content"><a class="title" href="/2022/10/09/GAN/" title="GAN">GAN</a><time datetime="2022-10-09T08:25:57.000Z" title="发表于 2022-10-09 16:25:57">2022-10-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/06/%E5%81%87%E5%A6%82%E7%94%9F%E6%B4%BB%E6%AC%BA%E9%AA%97%E4%BA%86%E4%BD%A0/" title="假如生活欺骗了你"><img src="https://w.wallhaven.cc/full/l3/wallhaven-l3edjp.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="假如生活欺骗了你"></a><div class="content"><a class="title" href="/2022/10/06/%E5%81%87%E5%A6%82%E7%94%9F%E6%B4%BB%E6%AC%BA%E9%AA%97%E4%BA%86%E4%BD%A0/" title="假如生活欺骗了你">假如生活欺骗了你</a><time datetime="2022-10-06T02:54:20.000Z" title="发表于 2022-10-06 10:54:20">2022-10-06</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">©2020 - 2022 By XR_Wang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax="">
  function butterfly_clock_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_injector_config();
  }
  </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax="" src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.js"></script><!-- hexo injector body_end end --></body></html>